{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application.**\n",
    "\n",
    "Min-Max scaling is a data normalization technique used to scale numerical features to a fixed range, typically [0,1] or [-1,1]. It is achieved by subtracting the minimum value of the feature and then dividing by the range of the feature (i.e., the difference between the maximum and minimum values). Min-Max scaling is useful when the range of values in different features is vastly different, and we want to ensure that each feature has equal importance during modeling.\n",
    "\n",
    "For example, consider a dataset of the heights of people in centimeters. The minimum height is 140 cm, and the maximum height is 200 cm. To scale this dataset using Min-Max scaling to the range of [0,1], we would first subtract 140 from each height value and then divide by 60 (i.e., the range of values). The resulting values would range from 0 to 1.\n",
    "\n",
    "**Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application.**\n",
    "\n",
    "The Unit Vector technique is another data normalization technique used to scale numerical features. Unlike Min-Max scaling, the Unit Vector technique scales the values of each feature to have unit norm, which means that the sum of the squares of the feature values is equal to 1. This technique is useful when the direction of the feature values is more important than the magnitude of the values.\n",
    "\n",
    "For example, consider a dataset of two features: height and weight. The height values range from 140 cm to 200 cm, and the weight values range from 40 kg to 100 kg. Using the Unit Vector technique, we would first calculate the norm of each data point (i.e., the square root of the sum of the squares of the feature values). Then we would divide each feature value by the norm of the data point. The resulting feature values would have unit norm, and the direction of the values would be preserved.\n",
    "\n",
    "**Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application.**\n",
    "\n",
    "PCA, or Principal Component Analysis, is a technique used for dimensionality reduction. It works by finding the principal components of a dataset, which are the directions of maximum variance in the data. The principal components are calculated using linear algebra, specifically by finding the eigenvectors of the covariance matrix of the data.\n",
    "\n",
    "PCA is useful when dealing with high-dimensional datasets, where the number of features is much larger than the number of observations. By reducing the number of features while retaining most of the variance in the data, PCA can improve the accuracy and efficiency of machine learning models.\n",
    "\n",
    "For example, consider a dataset of images, where each image is represented as a vector of pixel values. Each image may have thousands of pixels, making it difficult to train a machine learning model directly on the pixel values. By applying PCA to the dataset, we can identify the principal components of the pixel values and reduce the dimensionality of the dataset to a smaller number of features that capture most of the variance in the data.\n",
    "\n",
    "**Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept.**\n",
    "\n",
    "Feature Extraction and PCA are related concepts because PCA can be used as a feature extraction technique. By finding the principal components of a dataset, PCA can identify the underlying patterns and structure in the data and transform the original features into a new set of features that capture the most important information.\n",
    "\n",
    "For example, consider a dataset of images where each image is represented as a vector of pixel values. Applying PCA to the dataset would result in a new set of features that capture the principal components of the pixel values. These new features could then be used in a machine learning model to classify the images based on their content.\n",
    "\n",
    "**Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data.**\n",
    "\n",
    "To use Min-Max scaling to preprocess the data for a recommendation system for a food delivery service, we would first identify the numerical features that need to be scaled, such as price, rating, and delivery time. We would then apply the Min-Max scaling technique to each feature separately, scaling the values to the desired range\n",
    "\n",
    "**Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset.**\n",
    "\n",
    "To use PCA for dimensionality reduction in a stock price prediction project, the first step would be to normalize the features using standardization or Min-Max scaling. Next, we would compute the covariance matrix of the normalized features and then perform PCA to identify the principal components. The number of principal components to retain would be determined based on the amount of variance explained by the components. We would typically retain only those principal components that explain most of the variance in the data. This would help to reduce the dimensionality of the data and improve the performance of our stock price prediction model.\n",
    "\n",
    "**Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1.**\n",
    "\n",
    "\n",
    "Therefore, the Min-Max scaled dataset with values ranging from -1 to 1 would be [-1.0, -0.6, -0.2, 0.2, 0.6].\n",
    "\n",
    "**Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?**\n",
    "\n",
    "To perform feature extraction using PCA on the dataset containing the features [height, weight, age, gender, blood pressure], we would first normalize the features using standardization or Min-Max scaling. Next, we would compute the covariance matrix of the normalized features and then perform PCA to identify the principal components. The number of principal components to retain would depend on the amount of variance explained by the components.\n",
    "\n",
    "To determine the number of principal components to retain, we could use the scree plot, which shows the eigenvalues of the principal components in descending order. We would choose the number of principal components where the eigenvalues start to level off or become negligible. Another approach is to set a threshold for the amount of variance that we want to retain in the data, and then choose the number of principal components that explain at least that much variance.\n",
    "\n",
    "The optimal number of principal components to retain would depend on the specific characteristics of the dataset and the requirements of the prediction model. In general, we would want to retain as few principal components as possible while still retaining most of the variance in the data, as this would help to reduce the dimensionality of the data and improve the performance of our prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0, -0.5789473684210527, -0.052631578947368474, 0.4736842105263157, 1.0]\n"
     ]
    }
   ],
   "source": [
    "data = [1,5,10,15,20]\n",
    "scaled = []\n",
    "for i in data:\n",
    "    scaled.append(((i-min(data))/(max(data)-min(data))*2)-1)\n",
    "print(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
